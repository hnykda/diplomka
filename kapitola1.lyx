#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
\input{preamble}
\end_preamble
\use_default_options true
\master Main.lyx
\begin_modules
todonotes
theorems-ams
theorems-ams-extended
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "lmss" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command biber
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\branch childonly
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 2
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Bayesian probability
\end_layout

\begin_layout Standard
In this chapter, I summarize basics and preliminaries of Bayesian interpretation
 of probability and shortly compare it to frequentist approach.
 Reader is expected to know basic concepts from probability such as probability
 event, space, measure, product and sum rule, conditional and joint probability.
 All of these can be found in 
\begin_inset CommandInset citation
LatexCommand cite
key "Jaynes2003"
literal "true"

\end_inset

.
\end_layout

\begin_layout Section
Probability interpretations
\end_layout

\begin_layout Standard
As it is a case with other branches of mathematics, probability theory has
 multiple interpretations with theirs own strengths and weaknesses.
 In this particular case, it is a subject of dispute if the term 
\begin_inset Quotes eld
\end_inset

interpretations
\begin_inset Quotes erd
\end_inset

 should be used, since there is no single formal system 
\begin_inset Quotes eld
\end_inset

probability
\begin_inset Quotes erd
\end_inset

.
 For example, some of the leading interpretations fail to satisfy the most
 common Kolmogorov's axiomatization
\begin_inset Note Note
status collapsed

\begin_layout Axiom
\begin_inset CommandInset label
LatexCommand label
name "axm:Kolmogorov-axioms"

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
I spend two hours trying to format this down! For some reason, when a text
 of this part exceeds some length (now it is at its approximate maximum),
 it fails to compile with some stupid note! HATE YOU LATEX! Don't touch
 this, ever.
 Don't even try to add numbers or enumerate.
 It will hurt 
\end_layout

\end_inset

Kolmogorov axioms
\end_layout

\begin_layout Axiom
Probability is always positive
\end_layout

\begin_layout Axiom
\begin_inset Formula 
\[
P(E)\in\mathbb{R},P(E)\geq0\qquad\forall E\in F
\]

\end_inset


\end_layout

\begin_layout Axiom
Probability of all events equals one
\begin_inset Formula 
\[
P(\Omega)=1
\]

\end_inset


\end_layout

\begin_layout Axiom
\begin_inset Formula $\sigma$
\end_inset

-additivity
\begin_inset Formula 
\[
P(E_{1}\cup E_{2}\cup...)=P(E_{1})+P(E_{2})+...
\]

\end_inset


\end_layout

\end_inset

 and they still prove themselves useful
\begin_inset CommandInset citation
LatexCommand cite
key "interpretations"
literal "true"

\end_inset

.
 Other axiomatization has been proposed for different interpretation 
\begin_inset CommandInset citation
LatexCommand cite
key "Dupre2004"
literal "true"

\end_inset

 and some of the leading interpretations such as 
\begin_inset CommandInset citation
LatexCommand cite
key "Jaynes2003"
literal "true"

\end_inset

 don't even derive from 
\emph on
axioms
\emph default
, but rather 
\emph on
desiderata
\emph default

\begin_inset Foot
status collapsed

\begin_layout Plain Layout
(I) representations of plausibility are to be given by real numbers; (II)
 plausibilities are to be in qualitative agreement with common sense; and
 (III) the plausibilities are to be “consistent”, in the sense that anyone
 with the same information would assign the same real numbers to the plausibilit
ies
\end_layout

\end_inset

.
 Interpretations don't differ only in the underlying set of axioms, but
 also in their practical usage or their epistemological status.
 Mathematicians as well as philosophers has been tackling these issues at
 least for over five centuries.
\end_layout

\begin_layout Section
Why Bayesianism
\end_layout

\begin_layout Standard
It's hard to fully appreciate and understand main concepts and advantages
 of Bayesian reasoning if one is not familiar with other interpretations,
 such as frequentist.
 Its full description can be found in 
\begin_inset CommandInset citation
LatexCommand cite
key "frequency_prob"
literal "true"

\end_inset

, here we'll cover just the basics arising from the comparison.
 
\end_layout

\begin_layout Standard
The main idea of Bayesian interpretation is its subjective nature, where
 there is no such thing as 
\emph on
real
\emph default
 probability in the world, but probabilities are in actor's minds.
 Probability then represents agent's 
\emph on
state of knowledge
\emph default
 or 
\emph on
degree of belief
\emph default

\begin_inset CommandInset citation
LatexCommand cite
key "coxfreq,finettitheory,E.T.Jaynes1986"
literal "true"

\end_inset

.
 This is not a negligible formal difference – it has important consequences,
 such as the fact that all agents with different state of knowledge can
 assign different probabilities to the same event.
 In Bayesian framework, one explicitly convey uncertainty in his models
 and objects (such as random variables).
 
\end_layout

\begin_layout Standard
Another important aspect worth mentioning is also the fact that Bayes interpreta
tion allows doing predictions for events which haven't occurred yet (where
 frequentists are unable to do anything).
 This property is also connected to a fact that one can do partial (
\emph on
online
\emph default
) updates based on new evidence.
 
\end_layout

\begin_layout Section
Principles of Bayesian probability
\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\Var}[1]{\mathbf{#1}}
{\mathbf{#1}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\prob}[2]{#1(\Var{#2})}
{#1(\Var{#2})}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\probcond}[3]{#1(\Var{#2}|\Var{#3})}
{#1(\Var{#2}|\Var{#3})}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\probjoint}[3]{#1(\Var{#2},\Var{#3})}
{#1(\Var{#2},\Var{#3})}
\end_inset


\end_layout

\begin_layout Standard
Core idea of Bayesian interpretation is surely a famous Bayes theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:bayes-theorem"

\end_inset

, which is easily obtained from definition of conditional probability 
\begin_inset CommandInset citation
LatexCommand cite
key "Stuart1994"
literal "true"

\end_inset

.
\end_layout

\begin_layout Theorem

\emph on
Let P be a probability measure, 
\begin_inset Formula $\Var A$
\end_inset

 and 
\begin_inset Formula $\Var B$
\end_inset

 are events, 
\begin_inset Formula $\prob pB\neq0$
\end_inset

.
 Then
\emph default

\begin_inset Formula 
\begin{equation}
\probcond pAB=\prob pA\cdot\frac{\probcond pBA}{\prob pB}\label{eq:bayes-theorem}
\end{equation}

\end_inset


\end_layout

\begin_layout Theorem

\emph on
where: 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\prob pA$
\end_inset

 and 
\begin_inset Formula $\prob pB$
\end_inset

 are the probabilities of observing A and B independently.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\probcond pAB$
\end_inset

 is the probability of observing event A given that B is true.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\probcond pBA$
\end_inset

 is the probability of observing event B given that A is true.
 This factor is called 
\series bold
likelihood
\series default
.
 
\end_layout

\begin_layout Standard
To relate this simple formula to previous section, consider a scenario where
 one wants to use Bayesian framework for 
\emph on
inference.
 
\emph default
Suppose that 
\begin_inset Formula $\Var A$
\end_inset

 is a hypothesis whose probability can be affected by some evidence and
 
\begin_inset Formula $\Var B$
\end_inset

 is an evidence for this hypothesis.
 
\begin_inset Formula $\prob pA$
\end_inset

 in formula 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:bayes-theorem"

\end_inset

 can then be seen as a 
\series bold
prior probability
\series default
 – a probability one would assign to 
\begin_inset Formula $\Var A$
\end_inset

 is true 
\emph on
before
\emph default
 observing the evidence.
 Factor 
\begin_inset Formula $\probcond pBA$
\end_inset

, the 
\emph on
likelihood
\emph default
, represents how likely we expect to observe 
\begin_inset Formula $\Var B$
\end_inset

 
\emph on
given 
\emph default
that 
\begin_inset Formula $\Var A$
\end_inset

 is true.
 
\begin_inset Formula $\prob pB$
\end_inset

 is same for all possible hypothesis and serves as a normalizing factor
 (that is the reason why is often left out in many computations).
 And finally, 
\begin_inset Formula $\probcond pAB$
\end_inset

, which is the final 
\series bold
posterior probability
\series default
 which is the factor one usually care about – the probability of 
\begin_inset Formula $\Var A$
\end_inset

 after observing 
\begin_inset Formula $\Var B$
\end_inset

.
 
\end_layout

\begin_layout Standard
A factor 
\begin_inset Formula $\frac{\probcond pBA}{\prob pB}$
\end_inset

 has also quite useful interpretation and that is the overall impact of
 evidence 
\begin_inset Formula $\Var B$
\end_inset

 on the probability of 
\begin_inset Formula $\Var A$
\end_inset

.
 
\end_layout

\begin_layout Section
Conjugate distributions and exponential family
\end_layout

\begin_layout Standard
\begin_inset Flex TODO Note (inline)
status open

\begin_layout Plain Layout
Borrow this part from Mr Dedecius article page 3 - source code and cite
 it.
 There is informal definition right before Definition 2 and then consecutive
 much more detailed definitions.
 Also use rationale from before definition 2.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The updates can be significantly easier if 
\emph on
conjugate distributions
\emph default
 are used instead.
 
\end_layout

\begin_layout Section
Statistical model
\end_layout

\begin_layout Standard
Chosen interpretation has a nontrivial influence on what such concept as
 
\emph on
statistical model
\emph default
 is and how 
\emph on
inference 
\emph default
is done.
 I will follow traditional approach taken in 
\begin_inset CommandInset citation
LatexCommand cite
key "Kroese2014,McCullagh2002a"
literal "true"

\end_inset

 and extend it of some necessary concepts from 
\begin_inset CommandInset citation
LatexCommand cite
key "Bishop2013"
literal "true"

\end_inset

.
\end_layout

\begin_layout Standard
A statistical model is a pair of 
\begin_inset Formula $(S,M),$
\end_inset

 where 
\begin_inset Formula $S$
\end_inset

 is a set of possible observations (
\emph on
sample space
\emph default
) and 
\begin_inset Formula $M$
\end_inset

 is a set of probability distributions on 
\begin_inset Formula $S$
\end_inset

.
 Distribution in 
\begin_inset Formula $M$
\end_inset

 are expected to be approximately close to the 
\begin_inset Quotes eld
\end_inset

true
\begin_inset Quotes erd
\end_inset

 distribution which generates the data
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
There is a saying: 
\begin_inset Quotes eld
\end_inset

All models are wrong, but some of them are useful
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
, it is something like when humpty dumpty crasch his head towards a kings
 horse.
 Or a kings man.
 Or when the ants are marching two by two and the little one staps to sing
 humpty dumpty.
 
\end_layout

\end_inset

One of the main distinctions which can be made to separate families of statistic
al models is how distributions in 
\begin_inset Formula $M$
\end_inset

 are described:
\end_layout

\begin_layout Enumerate

\series bold
Parametric models
\series default
: in this case, the set 
\begin_inset Formula $M$
\end_inset

 is parameterized by some parameter 
\begin_inset Formula $\theta$
\end_inset

 and can have values from 
\emph on
finite
\emph default
 parameter space
\begin_inset Formula $\Theta\subseteq\mathbb{R}^{d}$
\end_inset

.
 In other words: 
\begin_inset Formula $M=\{P_{\theta}|\theta\in\Theta\}$
\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Nonparametric models
\series default
: this family is an unfortunate misnomer – nonparametric models also have
 parameters, but they differs from parametric models in a way that the parameter
 space is 
\begin_inset Formula $\Theta$
\end_inset

 is 
\emph on
infinite
\emph default
 – it is not fixed and can grow with the amount of data.
 
\end_layout

\begin_layout Standard
In Bayesian setting, parameters of the model have some prior distributions
 assigned.
 These distributions capture prior knowledge one posses before the application.
 For instance, this can be based on previous research or reliable enough
 observations.
 If there is no prior knowledge available, so called 
\emph on
uninformative 
\emph default
priors are being used instead.
 
\emph on
Uninformative 
\emph default
is again a misnomer – what is meant by these is the fact that they are not
 subjectively elicited.
 Fully Bayesian model is then a model in which 
\emph on
all 
\emph default
parameters have some prior assigned.
 An interesting property of Bayesian approach arise – random variables (includin
g latent variables) and parameters are treated in the same way.
 
\end_layout

\begin_layout Section
Statistical inference
\end_layout

\begin_layout Standard
Process of inferring properties of the data underlying distribution is called
 statistical inference
\begin_inset CommandInset citation
LatexCommand cite
key "Upton2008"
literal "true"

\end_inset

.
 Formally, it's justification of restricting parameter space based on the
 data (by e.g.
 choosing a point estimate for a given parameter).
 
\end_layout

\begin_layout Standard
Unfortunately, for many real world scenarios, the approach of directly inferring
 the properties is not possible.
 One of many reasons can be to high dimensionality of the task or the form
 of the posterior distribution may be to complex, let alone the fact that
 it does not have to have analytical solution
\begin_inset CommandInset citation
LatexCommand cite
key "Bishop:2006:PRM:1162264"
literal "true"

\end_inset

.
 In these scenarios, approximation methods are being used instead.
\end_layout

\begin_layout Subsection
Approximation methods
\begin_inset CommandInset label
LatexCommand label
name "subsec:Approximation-methods"

\end_inset


\end_layout

\begin_layout Standard
Using a breakdown from 
\begin_inset CommandInset citation
LatexCommand cite
key "Bishop:2006:PRM:1162264"
literal "true"

\end_inset

, approximation methods can be divided to two groups based on their stochastic
 or deterministic behavior.
 A notable example of the former is Markov chain Monte Carlo
\begin_inset CommandInset citation
LatexCommand cite
after "(Chap.11)"
key "Bishop:2006:PRM:1162264"
literal "true"

\end_inset

.
 A representative approach of the latter is e.g.
 variational inference described in detail in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Variational-inference"

\end_inset

.
 The main difference is the fact that stochastic schemes, 
\emph on
given infinite resources
\emph default
, are guaranteed to get the exact results and the approximation arise from
 the finite amount of those resources.
 On contrary, deterministic approximation schemes are based on 
\emph on
analytical approximations 
\emph default
to the posterior distribution and hence are generally not able to generate
 exact results.
 Both approaches are then complementary to each other, one being useful
 for situation where the second is unsuitable and vice versa.
 
\end_layout

\begin_layout Section
Variational Bayes inference
\begin_inset CommandInset label
LatexCommand label
name "sec:Variational-inference"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\kl}[2]{\text{{KL}}(#1||#2)}
{KL(#1||#2)}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\lueb}[1]{\mathcal{{L}}(#1)}
{\mathcal{L}(#1)}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\D}[1]{\text{ d}#1}
{\text{ d}#1}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\vec}[1]{\mathbb{#1}}
{\mathbb{#1}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\Exp}[1]{\exp\{#1\}}
{\exp\{#1\}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\E}[2][]{\text{\mathbb{E}}_{#1}[#2]}
{\text{\mathbb{E}}_{#1}[#2]}
\end_inset


\end_layout

\begin_layout Standard
In this work, a family of deterministic approximation methods 
\emph on
variational inference (
\emph default
or 
\emph on
variational Bayes) 
\emph default
is used, excellently described in 
\begin_inset CommandInset citation
LatexCommand cite
after "(p. 463)"
key "Bishop2013"
literal "true"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "Blei2017"
literal "true"

\end_inset

.
 This technique is based on using solution of an optimization problem to
 statistical inference, more exactly finding an input which minimize a specific
 functional.
 As was described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximation-methods"

\end_inset

, this method is guaranteed to get an exact result given some family of
 possible input functions over which one minimizes.
 The approximation arise from limiting the possible inputs, for instance
 by considering only quadratic functions or, as is widely used and is also
 our case, functions which factorizes in a specific way.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\probjoint pXZ$
\end_inset

 be a fully Bayesian model, where all prior distributions are given.
 Let denote the set of all parameters and all latent 
\begin_inset Formula $\Var Z=\{\vec z_{1},\ldots,\vec z_{N}\}$
\end_inset

 and the set of all observed variables 
\begin_inset Formula $\Var X=\{\vec{x_{1},\ldots,}\vec x_{N}\}$
\end_inset

.
 The goal of the inference is to find the posterior distribution 
\begin_inset Formula $\probcond pZX$
\end_inset

 and the distribution of the model evidence 
\begin_inset Formula $\prob pX$
\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Formula $\prob pX=\int\probjoint pZX\D{\Var Z}$
\end_inset

, which is usually unavailable
\end_layout

\end_inset

.
 Unfortunately, in many real world scenarios, 
\begin_inset Formula $\probcond pZX$
\end_inset

 is almost always intractable (by e.g.
 trying to integrate all configurations of the hidden variables in denominator).
 That is where 
\emph on
variational lower bound
\emph default
 comes in.
 Instead of trying to compute 
\begin_inset Formula $\probcond pZX$
\end_inset

 directly, we consider 
\begin_inset Formula $\prob qZ$
\end_inset

 which is as close approximation as possible to the former and has a convenient
 and tractable form (their expectations are computable).
 Furthermore, these approximate distributions can also have their own 
\emph on
variational parameters
\emph default
 which are considered to be in 
\begin_inset Formula $\Var Z$
\end_inset

 as well.
 As a measure of closeness between the approximate 
\begin_inset Formula $\prob qZ$
\end_inset

 and 
\begin_inset Formula $\probcond pZX$
\end_inset

, Kullback-Leibler (KL) divergence 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KL"

\end_inset

 is used
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
We omit arguments of distributions where possible for readability.
 Most often: 
\begin_inset Formula $q:=\prob qZ$
\end_inset

 and 
\begin_inset Formula $p=\probcond pZX$
\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\kl qp=-\int\prob qZ\ln\frac{\probcond pZX}{\prob qZ}\D{\Var Z}\label{eq:KL}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
In a case when 
\begin_inset Formula $\probcond pXZ=\prob qZ$
\end_inset

, Kullback-Leibler divergence is effectively zero.
 The goal is the following optimization problem:
\begin_inset Formula 
\begin{equation}
\prob qZ=\arg\min_{\prob qZ}\kl{\prob qZ}{\probcond pZX}.\label{eq:optim}
\end{equation}

\end_inset

 
\end_layout

\begin_layout Standard
The optimization 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:optim"

\end_inset

 cannot be performed directly.
 To compute 
\begin_inset Formula $\kl qp$
\end_inset

, the unknown evidence 
\begin_inset Formula $\prob pX$
\end_inset

 is needed, as can be seen from the following derivation
\begin_inset Formula 
\[
\kl q{\probcond pZX}=\E{\ln q}-\E{\ln\probcond pZX}=\E{\ln q}-\E{\ln\probjoint pZX}+\ln\prob pX
\]

\end_inset

.
\end_layout

\begin_layout Standard
Instead of trying to compute 
\begin_inset Formula $\kl qp$
\end_inset

, we are going to optimize an alternative objective that is equivalent to
 
\begin_inset Formula $\kl qp$
\end_inset

 up to an added constant.
 Let us then define 
\emph on
variational lower bound 
\emph default
(also called 
\emph on
ELBO
\emph default
) as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\lueb q=\int\prob qZ\ln\frac{\probjoint pXZ}{\prob qZ}\D{\Var Z}=\E{\ln\probjoint pZX}-\E{\ln\prob qZ}.\label{eq:elbo}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
It can be shown that
\begin_inset Formula $\lueb q$
\end_inset

 has an important property being a lower bound of the log probability 
\begin_inset Formula $\prob{\ln p}X\ge\lueb q$
\end_inset

.
 Henceforth, when one wishes to maximize marginal 
\begin_inset Formula $\prob pX$
\end_inset

, he can instead maximize its variational lower bound 
\begin_inset Formula $\lueb q$
\end_inset

.
 
\end_layout

\begin_layout Standard
Combining 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:elbo"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KL"

\end_inset

, the following relationship can be derived:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\ln\prob pX=\lueb q+\kl qp.
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\prob pX$
\end_inset

 doesn't depend on 
\begin_inset Formula $q$
\end_inset

, maximizing 
\begin_inset Formula $\lueb q$
\end_inset

 is possible and it is equivalent to minimizing 
\begin_inset Formula $\kl qp$
\end_inset

.
 
\end_layout

\begin_layout Standard
Again, since we don't know the true posterior distribution, we work with
 some family of distributions 
\begin_inset Formula $\prob qZ$
\end_inset

 for which 
\begin_inset Formula $\lueb q$
\end_inset

 becomes tractable and search for the candidate which maximizes it.
 Obviously, the choice of the distribution family is critical here – while
 it needs be tractable, it still needs to be flexible enough (as much as
 possible) to provide 
\emph on
accurate enough
\emph default
 approximation, goals usually going against each other.
 This is the part from where approximation arise in variational Bayes as
 has been discussed in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximation-methods"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Factorized distributions
\end_layout

\begin_layout Standard
A common choice for such a family of distributions described in the chapter
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Variational-inference"

\end_inset

 has been 
\emph on
factorized distributions
\emph default
 formalized in physics theory called 
\emph on
mean field theory
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Parisi.1988"
literal "true"

\end_inset

.
 The assumption on the family is quite simple – we treat each variable in
 
\begin_inset Formula $\Var Z$
\end_inset

 as independent, in other words, the family 
\series bold
factorizes
\series default
:
\begin_inset Formula 
\[
\prob qZ=\prod_{i=1}^{M}\prob{q_{i}}Z
\]

\end_inset


\end_layout

\begin_layout Standard
It is clear that the assumption is often not met.
 Variables are dependent in the real world – it is the reason why it is
 so hard to obtain the posterior distribution directly.
 
\end_layout

\begin_layout Standard
Notice that we do not require any specific form of 
\begin_inset Formula $\prob{q_{i}}{Z_{i}}$
\end_inset

.
 Also, it is worth noting that this is 
\emph on
not
\emph default
 a model of the observed data – it is the ELBO and KL minimization problem,
 which connects this to the model and data.
\end_layout

\begin_layout Section
Coordinate ascent mean-field variational
\end_layout

\begin_layout Standard
Coordinate ascent mean-field variational (
\emph on
CAVI
\emph default
) is a commonly used algorithm for solving optimization problem 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:optim"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Blei2017"
literal "true"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Bishop:2006:PRM:1162264"
literal "true"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Derivation
\end_layout

\begin_layout Subsubsection*
Optimal 
\begin_inset Formula $\prob{q_{i}^{*}}{Z_{i}}$
\end_inset


\end_layout

\begin_layout Standard
First, consider the complete conditional of 
\begin_inset Formula $\Var{Z_{i}}$
\end_inset

, which is 
\begin_inset Formula $\probcond p{Z_{i}}{Z_{-i},X}$
\end_inset

.
 If we fix all other variational factors 
\begin_inset Formula $\prob{q_{l}}{Z_{l}},l\ne i$
\end_inset

, the optimal 
\begin_inset Formula $\prob{q_{i}}{Z_{i}}$
\end_inset

 satisfies the following
\begin_inset Foot
status open

\begin_layout Plain Layout
By 
\begin_inset Formula $\E[-i]{...}$
\end_inset

, we denote expectation over all 
\begin_inset Formula $q$
\end_inset

 distributions 
\emph on
except 
\begin_inset Formula $q_{i}$
\end_inset

.
 
\emph default
Similarly, 
\begin_inset Formula $\Var{Z_{\{-i\}}}$
\end_inset

 means all latent variables except 
\emph on

\begin_inset Formula $\Var{Z_{i}}$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\prob{q_{i}^{*}}{Z_{i}}\propto\Exp{{\E[-i]{\ln\probcond p{Z_{i}}{Z_{-j},X}}}}\propto\Exp{{\E[-i]{\ln\probjoint p{Z_{i},Z_{\{-i\}}}X}}}\label{eq:ascent-update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where in the last term, we use the fact that 
\begin_inset Formula $\prob{q_{-i}}{Z_{-i}}=\prod_{l\ne i}\prob{q_{l}}{Z_{l}}$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Obtaining KL
\end_layout

\begin_layout Standard
Let us now rewrite 
\begin_inset Formula $\lueb q$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:elbo"

\end_inset

 as a function of 
\begin_inset Formula $\prob{q_{i}}{Z_{i}}$
\end_inset


\begin_inset Formula 
\begin{equation}
\lueb{q_{i}}=\E[i]{{\E[-i]{\ln\probjoint p{Z_{i},Z_{\{-i\}}}X}}}-\E[i]{\ln\prob{q_{i}}{Z_{i}}}+C\label{eq:negkl}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where in the first term is just an iterated expectation and in the second
 we retain only product term containing 
\begin_inset Formula $\prob{q_{i}}{Z_{i}},$
\end_inset

 while other parts can be moved to a constant 
\begin_inset Formula $C$
\end_inset

 thanks to using factorized distribution.
\end_layout

\begin_layout Standard
Now it's easy to see that 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:negkl"

\end_inset

 is a negative KL divergence between 
\begin_inset Formula $\prob{q_{i}}{Z_{i}}$
\end_inset

 and 
\begin_inset Formula $\prob{q_{i}^{*}}{Z_{i}}$
\end_inset

.
 That gives as all necessary part for the CAVI algorithm as described in
 
\begin_inset CommandInset citation
LatexCommand cite
key "Blei2017"
literal "true"

\end_inset

:
\end_layout

\begin_layout Algorithm
\begin_inset CommandInset label
LatexCommand label
name "alg:CAVI"

\end_inset

CAVI
\end_layout

\begin_layout Algorithm

\series bold
Input: 
\series default
A model 
\begin_inset Formula $\probjoint pXZ$
\end_inset

, a dataset 
\begin_inset Formula $\Var X$
\end_inset


\end_layout

\begin_layout Algorithm

\series bold
Output: 
\series default
A variational density 
\begin_inset Formula $\prob qZ=\prod_{i=1}^{m}\prob{q_{i}}{Z_{i}}$
\end_inset


\end_layout

\begin_layout Algorithm

\series bold
Initialize:
\series default
 Variational factors 
\begin_inset Formula $\prob{q_{i}}{Z_{i}}$
\end_inset


\end_layout

\begin_layout Algorithm

\series bold
while 
\series default
the 
\begin_inset Formula $\lueb q$
\end_inset

 has not converged
\end_layout

\begin_layout Algorithm

\series bold
\shape italic
\begin_inset space \thinspace{}
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $i\in\{1,...,m\}$
\end_inset

 do
\end_layout

\begin_layout Algorithm

\shape italic
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

Set 
\begin_inset Formula $\prob{q_{i}}{Z_{i}}\propto\Exp{{\E[-i]{\ln\probjoint p{Z_{i},Z_{\{-i\}}}X}}}$
\end_inset


\end_layout

\begin_layout Algorithm
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\series bold
end
\end_layout

\begin_layout Algorithm
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

Compute 
\begin_inset Formula $\lueb q=\E{\ln\probjoint pZX}-\E{\ln\prob qZ}$
\end_inset


\end_layout

\begin_layout Algorithm

\series bold
end
\end_layout

\begin_layout Algorithm

\series bold
return 
\begin_inset Formula $\prob qZ$
\end_inset


\end_layout

\begin_layout Standard
It is guaranteed that this algorithm converge to a local minimum.
\end_layout

\begin_layout Section
Example
\end_layout

\begin_layout Standard
\begin_inset Flex TODO Note (inline)
status collapsed

\begin_layout Plain Layout
Combination of all of the above in a single example.
 Ideally with nice visualization.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Let us demonstrate the above with an example from 
\begin_inset CommandInset citation
LatexCommand cite
key "Bishop:2006:PRM:1162264"
literal "true"

\end_inset

.
 
\end_layout

\begin_layout Paragraph
The model
\end_layout

\begin_layout Standard
Consider the i.i.d dataset 
\begin_inset Formula $\mathbf{X}=\{x_{1},\cdots,x_{N}\}$
\end_inset

 generated by (unknown) Gaussian distribution
\begin_inset space ~
\end_inset


\begin_inset Formula $\mathcal{\Var X\sim N}(\mu,\tau^{-1})$
\end_inset

.
 The goal is to infer posterior 
\begin_inset Formula $\probcond p{\mu,\tau}X$
\end_inset

 and the joint probability is
\begin_inset Formula 
\[
\prob p{X,\mu,\tau}=\probcond pX{\mu,\tau}\probcond p{\mu}{\tau}\prob p{\tau}
\]

\end_inset


\end_layout

\begin_layout Paragraph
Factorized distribution
\end_layout

\begin_layout Standard
Let us now approximate 
\begin_inset Formula $\probcond p{\mu,\tau}X$
\end_inset

 by 
\begin_inset Formula $\probjoint q{\mu}{\tau}$
\end_inset

 with the assumption that 
\begin_inset Formula $q$
\end_inset

 factorizes: 
\begin_inset Formula $\probjoint q{\mu}{\tau}=\prob q{\mu}\prob q{\tau}$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Conjugated priors
\end_layout

\begin_layout Standard
The complete data likelihood is Gaussian distribution and hence in exponential
 family.
 We set a non-informative conjugated priors for the 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\tau$
\end_inset

 as follows
\begin_inset Flex TODO Note (inline)
status collapsed

\begin_layout Plain Layout
Is it correct? Is it likelihood to which we set conjugated priors?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mu & \sim\mathcal{N}(\mu_{0},(\lambda_{0}\tau)^{-1})\\
\tau & \sim\text{Gamma}(a_{0},b_{0})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where the hyperparameters 
\begin_inset Formula $\mu_{0},\lambda_{0},a_{0},b_{0}$
\end_inset

 are initially set to some small positive number.
 
\end_layout

\begin_layout Paragraph
Form of 
\begin_inset Formula $\prob q{\mu}$
\end_inset

 and 
\begin_inset Formula $\prob q{\tau}$
\end_inset


\end_layout

\begin_layout Standard
This is usually the hardest part of variational inference.
 The derivation of the following terms is according to 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ascent-update"

\end_inset

 and in detail can be found in 
\begin_inset CommandInset citation
LatexCommand cite
key "Bishop:2006:PRM:1162264"
literal "true"

\end_inset

.
\end_layout

\begin_layout Standard
The derivations yields following for 
\begin_inset Formula $\prob{q_{\mu}^{*}}{\mu}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\prob{q_{\mu}^{*}}{\mu} & \sim\mathcal{N}(\mu\mid\mu_{N},\lambda_{N}^{-1})\\
\mu_{N}= & \frac{\lambda_{0}\mu_{0}+N\bar{x}}{\lambda_{0}+N}\\
\lambda_{N} & =(\lambda_{0}+N)\E[\tau]{\tau}=(\lambda_{0}+N)\frac{a_{N}}{b_{N}}\\
\bar{x}= & \frac{1}{N}\sum_{n=1}^{N}x_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and for 
\begin_inset Formula $\prob{q_{\tau}^{*}}{\tau}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\prob{q_{\tau}^{*}}{\tau} & \sim\text{Gamma(\tau\mid a_{N},b_{N})}\\
a_{N} & =a_{0}+\frac{N+1}{2}\\
b_{N} & =b_{0}+\frac{1}{2}\E[\mu]{\sum_{n=1}^{N}(x_{n}-\mu)^{2}+\lambda_{0}(\mu-\mu_{0})^{2}}=\\
 & =b_{0}+\frac{1}{2}\left[(\lambda_{0}+N)\left(\lambda_{N}^{-1}+\mu_{N}^{2}\right)-2\left(\lambda_{0}\mu_{0}+\sum_{n=1}^{N}x_{n}\right)\mu_{N}+\left(\sum_{n=1}^{N}x_{n}^{2}\right)+\lambda_{0}\mu_{0}^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph
Perform updates based on CAVI
\end_layout

\begin_layout Standard
Initially, compute 
\begin_inset Formula $N,\sum_{n=1}^{N}x_{n},\sum_{n=1}^{N}x_{n}^{2}$
\end_inset

 and set 
\begin_inset Formula $\lambda_{N,t}$
\end_inset

 to some random value.
 Then iterate these steps until convergence:
\end_layout

\begin_layout Enumerate
plug in 
\begin_inset Formula $\lambda_{N,t}$
\end_inset

 to obtain 
\begin_inset Formula $b_{N,t}$
\end_inset


\end_layout

\begin_layout Enumerate
compute new 
\begin_inset Formula $\lambda_{N,t+1}$
\end_inset

 based on 
\begin_inset Formula $b_{N,t}$
\end_inset

 and all other terms needed
\end_layout

\begin_layout Standard
\begin_inset Flex TODO Note (inline)
status collapsed

\begin_layout Plain Layout
Is it correct that 
\begin_inset Formula $a_{N},\mu_{N}$
\end_inset

 doesn't update? The 
\begin_inset Quotes eld
\end_inset

N
\begin_inset Quotes erd
\end_inset

 suffix here seems to be quite redundant.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Results 
\end_layout

\begin_layout Standard
After 
\begin_inset Formula $m$
\end_inset

 iterations, we are now having new values of all parameters including hyperparam
eters.
 Hence we are able to approximate the posterior distribution.
 The joint probability is
\begin_inset Formula 
\begin{align*}
\prob p{X,\mu,\tau} & =\probcond pX{\mu,\tau}\probcond p{\mu}{\tau}\prob p{\tau}=\\
= & \prod_{n=1}^{N}\mathcal{N}(\vec{x_{n}}|\mu_{N},\tau_{N}^{-1})\mathcal{N}(\mu_{N},(\lambda_{N}\tau_{N})^{-1})\text{Gamma}(a_{N},b_{N})
\end{align*}

\end_inset


\begin_inset Flex TODO Note (inline)
status collapsed

\begin_layout Plain Layout
Is it correct, or should it be 
\begin_inset Formula $\mathcal{N}(X|\mu_{N},\tau_{N}^{-1})\cdot\mathcal{N}(\mu_{0},(\lambda_{0}\tau_{N})^{-1})\cdot\text{Gamma}(a_{0},b_{0})$
\end_inset

.
 How the hell I get the posterior!?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
g
\begin_inset Branch childonly
inverted 0
status collapsed

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Nemazat - je to potřeba abych viděl citace v \SpecialChar LyX

\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "library"
options "bibtotoc,plain"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
printbibliography
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_body
\end_document
